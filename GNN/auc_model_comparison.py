# -*- coding: utf-8 -*-
"""AUC Model Comparison.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2tVNIROztgpHSrPmXeVlphhTFepPoQh
"""

import pandas as pd
import numpy as np
import time
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, precision_recall_curve
import torch
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GCNConv
from sklearn.metrics import f1_score

class GCN(torch.nn.Module):
    def __init__(self, data, hidden_channels):
        super().__init__()
        torch.manual_seed(42)
        self.conv1 = GCNConv(data.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, len(torch.unique(data.y)))

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv3(x, edge_index)
        return x

def train(data, model, optimizer, criterion):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

def evaluate(mask, data, model):
    model.eval()
    with torch.no_grad():
        out = model(data.x, data.edge_index)
        pred = out.argmax(dim=1)
        true_labels = data.y[mask].cpu().numpy()
        pred_labels = pred[mask].cpu().numpy()
        correct = pred[mask].eq(data.y[mask])
        accuracy = int(correct.sum()) / int(mask.sum())
        f1 = f1_score(true_labels, pred_labels, average="macro", zero_division=0)
    return accuracy, f1, out[mask]

def main():
    features_path = 'adjusted_users.csv'
    edges_path = 'edge.csv'

numeric_columns = [
    "follower_count", "following_count", "tweet_count", "listed_count",
    "year_created", "description_True", "description_False",
    "entities_True", "entities_False", "location_True", "location_False",
    "protected_True", "protected_False", "url_True", "url_False",
    "verified_True", "verified_False", "withheld_True", "withheld_False",
    "bot_True", "bot_False"
]

users = pd.read_csv(features_path, low_memory=False)
edges = pd.read_csv(edges_path)

# Convert IDs to numeric
user_id_mapping = pd.Categorical(users['id'])
users['id'] = user_id_mapping.codes
edges = edges[
    edges['source_id'].isin(user_id_mapping.categories) &
    edges['target_id'].isin(user_id_mapping.categories)
]
edges['source_id'] = pd.Categorical(edges['source_id'], categories=user_id_mapping.categories).codes
edges['target_id'] = pd.Categorical(edges['target_id'], categories=user_id_mapping.categories).codes

filtered_features = users[numeric_columns].fillna(0).apply(pd.to_numeric, errors='coerce')
features = torch.tensor(filtered_features.values, dtype=torch.float32)
label_mapping = {"human": 0, "bot": 1}
labels = torch.tensor(users['label'].map(label_mapping).values, dtype=torch.long)

edge_index = torch.tensor(edges[['source_id', 'target_id']].values.T, dtype=torch.long)

data = Data(x=features, edge_index=edge_index, y=labels)
data = NormalizeFeatures()(data)

perm = torch.randperm(data.num_nodes)
train_idx = perm[:int(data.num_nodes * 0.6)]
val_idx = perm[int(data.num_nodes * 0.6):int(data.num_nodes * 0.8)]
test_idx = perm[int(data.num_nodes * 0.8):]

data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)
data.train_mask[train_idx] = True

data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)
data.val_mask[val_idx] = True

data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)
data.test_mask[test_idx] = True

# GCN Training
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
gcn_model = GCN(data, hidden_channels=16).to(device)
data = data.to(device)
optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

# Train GCN
print("Training GCN...")
for epoch in range(200):
    loss = train(data, gcn_model, optimizer, criterion)
    val_acc, val_f1, _ = evaluate(data.val_mask, data, gcn_model)
    if epoch % 10 == 0:
        print(f"Epoch {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}")

print("Evaluating GCN...")
test_acc, test_f1, gcn_output = evaluate(data.test_mask, data, gcn_model)
print(f"GCN Test Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}")

gcn_predictions = F.softmax(gcn_output, dim=1)[:, 1].cpu().numpy()

scaler = StandardScaler()
features_scaled = scaler.fit_transform(filtered_features)

# Random Forest Classifier
rfc = RandomForestClassifier(max_depth=15, n_estimators=156, random_state=42, n_jobs=-1)
rfc.fit(features_scaled, labels.numpy())
rfc_predictions = rfc.predict_proba(features_scaled)[:, 1]

# AdaBoost Classifier
ada = AdaBoostClassifier(random_state=42, algorithm='SAMME', learning_rate=0.97, n_estimators=5)
ada.fit(features_scaled, labels.numpy())
ada_predictions = ada.predict_proba(features_scaled)[:, 1]

# Support Vector Machine (SVM)
svm_model = svm.SVC(probability=True, random_state=42)
svm_model.fit(features_scaled, labels.numpy())
svm_predictions = svm_model.predict_proba(features_scaled)[:, 1]

# K-Nearest Neighbors (KNN)
knn = KNeighborsClassifier()
knn.fit(features_scaled, labels.numpy())
knn_predictions = knn.predict_proba(features_scaled)[:, 1]

# AUC Scores
models = {
    "RFC": rfc_predictions,
    "ADA": ada_predictions,
    "GCN": gcn_predictions,
    "SVM": svm_predictions,
    "KNN": knn_predictions
}

auc_scores = {model_name: roc_auc_score(labels.numpy(), predictions) for model_name, predictions in models.items()}
print("AUC Scores for Models:")
for model_name, auc in auc_scores.items():
    print(f"{model_name}: {auc:.4f}")

# Plot AUC
plt.figure(figsize=(8, 6))
plt.bar(auc_scores.keys(), auc_scores.values(), color=['blue', 'orange', 'green', 'red', 'purple'])
plt.title("AUC Scores Model Comparison")
plt.ylabel("AUC Score")
plt.ylim(0.0, 1.0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Precision Recall Curve
def plot_precision_recall(models, true_labels, title="Precision-Recall Curves"):
    plt.figure(figsize=(10, 8))
    for model_name, predictions in models.items():
        precision, recall, _ = precision_recall_curve(true_labels, predictions)
        plt.plot(recall, precision, label=model_name)
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title(title)
    plt.legend(loc='lower left')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

plot_precision_recall(models, labels.numpy(), title="Precision-Recall Curves for Models")

if __name__ == "__main__":
    main()